[
{
	"uri": "/basics/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": " Running the binary Download the packaged archive for your platform from the downloads page and extract the package to a shared location in your drive, like /opt/local/bin.\nRun Dkron with default setting: dkron agent --server\nNavigate to http://localhost:8080\nBy default dkron will start with a file based, embedded KV store called BoltDB, it is functional for a single node demo but does not offers clustering or HA.\n Installing the package Debian repo APT repository:\ndeb [trusted=yes] https://apt.fury.io/victorcoder/ /  Then install: sudo apt-get install dkron\nYUM repo YUM repository:\n[dkron] name=Dkron Pro Private Repo baseurl=https://yum.fury.io/victorcoder/ enabled=1 gpgcheck=0  Then install: sudo apt-get install dkron\nThis will start Dkron as a system service and the place example configuration file under /etc/dkron/dkron.yml\nRunning in Docker Dkron provides an official Docker image vi Dockerhub that can be used for deployment on any system running Docker.\nLaunching Dkron on a new container Here’s a quick one-liner to get you off the ground (please note, we recommend further configuration for production deployments below):\ndocker run -d -p 8080:8080 --name dkron dkron/dkron agent --server  This will launch a Dkron server on port 8080 by default. You can use docker logs -f dkron to follow the rest of the initialization progress. Once the Dkron startup completes you can access the app at localhost:8080\nSince Docker containers have their own ports and we just map them to the system ports as needed it’s easy to move Dkron onto a different system port if you wish. For example running Dkron on port 12345:\ndocker run -d -p 12345:8080 --name dkron dkron/dkron  Mounting a mapped file storage volume In its default configuration Dkron uses the local filesystem to run a BoltDB embedded database to store its own application data. The end result is that your Dkron application data will be on disk inside your container and lost if you ever remove the container.\nTo persist your data outside of the container and make it available for use between container launches we can mount a local file path inside our container.\ndocker run -d -p 8080:8080 -v ~/dkron.db:/dkron.db --name dkron dkron/dkron agent --server  Now when you launch your container we are mounting that file from our local filesystem into the container.\n"
},
{
	"uri": "/pro/quick-start/",
	"title": "Quick start",
	"tags": [],
	"description": "",
	"content": " Getting started Dkron Pro provides a clustering backend store out of the box based on etcd.\nTo configure the storage a sample etcd.conf.yaml file is provided in /etc/dkron path. Editing the file, allows to configure several options for the embedded store.\nThe location of the store configuration can be set in the command line or in the dkron config file /etc/dkron/dkron.yml using etcd-config-file-path parameter.\nStarting a single node Works out of the box, good for non HA installations.\n System service: If no changes are done to the default config files, dkron will start as a service in single mode. Command line: Running a single node with default config can be done by running: dkron agent --server  Check your server is working: curl localhost:8080/v1\nSimple as that, now it is time to add some jobs:\ncurl localhost:8080/v1/jobs -XPOST -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;timezone\u0026#34;: \u0026#34;Europe/Berlin\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;Platform Team\u0026#34;, \u0026#34;owner_email\u0026#34;: \u0026#34;platform@example.com\u0026#34;, \u0026#34;disabled\u0026#34;: false, \u0026#34;tags\u0026#34;: { \u0026#34;dkron_server\u0026#34;: \u0026#34;true\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;allow\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;date\u0026#34; } }\u0026#39;"
},
{
	"uri": "/usage/target-nodes-spec/",
	"title": "Target nodes spec",
	"tags": [],
	"description": "",
	"content": " Target nodes spec You can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run.\nThe target node syntax: [tag-value]:[count]\n Examples: Target all nodes with a tag:\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;role#quot;: #quot;web#quot;\") --|Run Job|N1[\"Node1 tags: #quot;role#quot;: #quot;web#quot;\"] J --|Run Job|N2[\"Node2 tags: #quot;role#quot;: #quot;web#quot;\"] J --|Run Job|N3[\"Node2 tags: #quot;role#quot;: #quot;web#quot;\"]  Target only one nodes of a group of nodes with a tag:\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web:1\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;role#quot;: #quot;web:1#quot;\") --|Run Job|N1[\"Node1 tags: #quot;role#quot;: #quot;web#quot;\"] J -.- N2[\"Node2 tags: #quot;role#quot;: #quot;web#quot;\"] J -.- N3[\"Node2 tags: #quot;role#quot;: #quot;web#quot;\"]  Dkron will try to run the job in the amount of nodes indicated by that count having that tag.\n"
},
{
	"uri": "/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": "  Installation Running the binary Download the packaged archive for your platform from the downloads page and extract the package to a shared location in your drive, like /opt/local/bin. Run Dkron with default setting: dkron agent --server Navigate to http://localhost:8080 By default dkron will start with a file based, embedded KV store called BoltDB, it is functional for a single node demo but does not offers clustering or HA. Installing the package Debian repo APT repository:\n  Getting started Introduction Dkron nodes can work in two modes, agents or servers. A Dkron agent is a cluster member that can handle job executions, run your scripts and return the resulting output to the server. A Dkron server is also a cluster member that send job execution queries to agents or other servers, so servers can execute jobs too. The main distinction is that servers order job executions, can be used to schedule jobs, handles data storage and participate on leader election.\n  Configuration Configuration sources Settings can be specified in three ways (in order of precedence): Command line arguments. Environment variables starting with DKRON_ dkron.json config file Config file example # Dkron example configuration file # backend: etcd # backend-machine: 127.0.0.1:2379 # server: false # log-level: debug # tags: # role: web # datacenter: east # keyspace: dkron # encrypt: a-valid-key-generated-with-dkron-keygen # join: # - 10.0.0.1 # - 10.0.0.2 # - 10.\n  "
},
{
	"uri": "/usage/cron-spec/",
	"title": "Cron spec",
	"tags": [],
	"description": "",
	"content": " CRON Expression Format A cron expression represents a set of times, using 6 space-separated fields.\nField name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ? Month | Yes | 1-12 or JAN-DEC | * / , - Day of week | Yes | 0-6 or SUN-SAT | * / , - ?  Note: Month and Day-of-week field values are case insensitive. \u0026ldquo;SUN\u0026rdquo;, \u0026ldquo;Sun\u0026rdquo;, and \u0026ldquo;sun\u0026rdquo; are equally accepted.\nSpecial Characters\nAsterisk ( * )\nThe asterisk indicates that the cron expression will match for all values of the field; e.g., using an asterisk in the 5th field (month) would indicate every month.\nSlash ( / )\nSlashes are used to describe increments of ranges. For example 3-59\u0026frasl;15 in the 1st field (minutes) would indicate the 3rd minute of the hour and every 15 minutes thereafter. The form \u0026ldquo;*\\/\u0026hellip;\u0026rdquo; is equivalent to the form \u0026ldquo;first-last/\u0026hellip;\u0026rdquo;, that is, an increment over the largest possible range of the field. The form \u0026ldquo;N/\u0026hellip;\u0026rdquo; is accepted as meaning \u0026ldquo;N-MAX/\u0026hellip;\u0026rdquo;, that is, starting at N, use the increment until the end of that specific range. It does not wrap around.\nComma ( , )\nCommas are used to separate items of a list. For example, using \u0026ldquo;MON,WED,FRI\u0026rdquo; in the 5th field (day of week) would mean Mondays, Wednesdays and Fridays.\nHyphen ( - )\nHyphens are used to define ranges. For example, 9-17 would indicate every hour between 9am and 5pm inclusive.\nQuestion mark ( ? )\nQuestion mark may be used instead of \u0026lsquo;*\u0026rsquo; for leaving either day-of-month or day-of-week blank.\nPredefined schedules You may use one of several pre-defined schedules in place of a cron expression.\nEntry | Description | Equivalent To ----- | ----------- | ------------- @yearly (or @annually) | Run once a year, midnight, Jan. 1st | 0 0 0 1 1 * @monthly | Run once a month, midnight, first of month | 0 0 0 1 * * @weekly | Run once a week, midnight on Sunday | 0 0 0 * * 0 @daily (or @midnight) | Run once a day, midnight | 0 0 0 * * * @hourly | Run once an hour, beginning of hour | 0 0 * * * * @minutely | Run once a minute, beginning of minute | 0 * * * * *  Intervals You may also schedule a job to execute at fixed intervals. This is supported by formatting the cron spec like this:\n@every \u0026lt;duration\u0026gt;  where \u0026ldquo;duration\u0026rdquo; is a string accepted by time.ParseDuration (http://golang.org/pkg/time/#ParseDuration).\nFor example, \u0026ldquo;@every 1h30m10s\u0026rdquo; would indicate a schedule that activates every 1 hour, 30 minutes, 10 seconds.\nNote: The interval does not take the job runtime into account. For example, if a job takes 3 minutes to run, and it is scheduled to run every 5 minutes, it will have only 2 minutes of idle time between each run.\nFixed times You may also want to schedule a job to be executed once. This is supported by formatting the cron spec like this:\n@at \u0026lt;datetime\u0026gt;  Where \u0026ldquo;datetime\u0026rdquo; is a string accepted by time.Parse in RFC3339 format (https://golang.org/pkg/time/#Parse).\nFor example, \u0026ldquo;@at 2018-01-02T15:04:00Z\u0026rdquo; would run the job on the specified date and time assuming UTC timezone.\nTime zones Dkron is able to schedule jobs in time zones, if you specify the timezone parameter in a job definition.\nIf the time zone is not specified, the following rules apply:\nAll interpretation and scheduling is done in the machine\u0026rsquo;s local time zone (as provided by the Go time package (http://www.golang.org/pkg/time).\nBe aware that jobs scheduled during daylight-savings leap-ahead transitions will not be run!\nIf you specify timezone the job will be scheduled taking into account daylight-savings and leap-ahead transitions, running the job in the actual time in the specified time zone.\n"
},
{
	"uri": "/usage/executors/",
	"title": "Executors",
	"tags": [],
	"description": "",
	"content": " Executors Executors plugins are the main mechanism of execution in Dkron. They implement different \u0026ldquo;types\u0026rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes.\nFor example, the built-in shell executor, will run the indicated command in the target node.\nNew plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.\nDkron Pro have commercially supported executors\n HTTP Executor   Shell Executor   "
},
{
	"uri": "/basics/getting-started/",
	"title": "Getting started",
	"tags": [],
	"description": "",
	"content": " Introduction Dkron nodes can work in two modes, agents or servers.\nA Dkron agent is a cluster member that can handle job executions, run your scripts and return the resulting output to the server.\nA Dkron server is also a cluster member that send job execution queries to agents or other servers, so servers can execute jobs too.\nThe main distinction is that servers order job executions, can be used to schedule jobs, handles data storage and participate on leader election.\nDkron clusters have a leader, the leader is responsible of starting job execution queries in the cluster.\nAny Dkron agent or server acts as a cluster member and it\u0026rsquo;s available to run scheduled jobs.\nYou can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run. This gives an unprecedented level of flexibility in runnig jobs across a cluster of any size and with any combination of machines you need.\nAll the execution responses will be gathered by the scheduler and stored in the database.\nBackend stores Dkron relies on the key-value store for data storage, an instance of the distributed store can be run in the same machines as Dkron or connect it to an already existing cluster.\nBy default dkron will start with a file based, embedded KV store called BoltDB, it is functional for a single node demo but does not offers clustering or HA.\n It is compatible with etcd, Consul, Zookeeper, DynamoDB, BoltDB and partially with Redis. For instructions on how to install and configure any one of these systems refer to their official sites:\n etcd Consul ZooKeeper Redis DynamoDB  Installation See the installation.\nConfiguration See the configuration.\nUsage By default Dkron uses the following ports:\n 8946 for communicating between agents 8080 for HTTP for the API and Dashboard 6868 for RPC comunication between agents.  Be sure you have opened this ports (or the ones that you configured) in your firewall or AWS security groups.\n By default dkron will use the embedded BoltDB KV store. A different store can be specified setting backend and backend-machines flag in the config file, env variables or as a command line flag.\nTo start a Dkron server instance:\ndkron agent --server  Time to add the first job:\nThis job will only run in just one dkron_server node due to the node count in the tag. Refer to the target node spec for details.\n curl localhost:8080/v1/jobs -XPOST -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;timezone\u0026#34;: \u0026#34;Europe/Berlin\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;Platform Team\u0026#34;, \u0026#34;owner_email\u0026#34;: \u0026#34;platform@example.com\u0026#34;, \u0026#34;disabled\u0026#34;: false, \u0026#34;tags\u0026#34;: { \u0026#34;dkron_server\u0026#34;: \u0026#34;true:1\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;allow\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;date\u0026#34; } }` That\u0026rsquo;s it!\nTo start configuring an HA installation of Dkron follow the clustering guide "
},
{
	"uri": "/usage/processors/",
	"title": "Processors",
	"tags": [],
	"description": "",
	"content": " Execution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it\u0026rsquo;s very flexible and per Job, examples of operations this plugins can do:\n Execution output storage, forwarding or redirection. Notification Monitoring  For example, Processor plugins can be used to redirect the output of a job execution to different targets.\nCurrently Dkron provides you with some built-in plugins but the list keeps growing. Some of the features previously implemented in the application will be progessively moved to plugins.\nBuilt-in processors Dkron provides the following built-in processors:\n not specified - Store the output in the key value store (Slow performance, good for testing, default method) log - Output the execution log to Dkron stdout (Good performance, needs parsing) syslog - Output to the syslog (Good performance, needs parsing) files - Output to multiple files (Good performance, needs parsing)  Dkro Pro provides you with several more processors.\nAll plugins accepts one configuration option: forward Indicated if the plugin must forward the original execution output. This allows for chaining plugins and sending output to different targets at the same time.\n File Processor   Log Processor   Syslog Processor   "
},
{
	"uri": "/usage/",
	"title": "Usage",
	"tags": [],
	"description": "",
	"content": "  Target nodes spec Target nodes spec You can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run. The target node syntax: [tag-value]:[count] Examples: Target all nodes with a tag: { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;role#quot;: #quot;web#quot;\") --|Run Job|N1[\"\n  Cron spec CRON Expression Format A cron expression represents a set of times, using 6 space-separated fields. Field name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ?\n  Executors Executors Executors plugins are the main mechanism of execution in Dkron. They implement different \u0026ldquo;types\u0026rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes. For example, the built-in shell executor, will run the indicated command in the target node. New plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.\n  HTTP Executor HTTP executor can send a request to an HTTP endpoint Configuration Params: method: Request method in uppercase url: Request url headers: Json string, such as \u0026quot;[\\\u0026quot;Content-Type: application/json\\\u0026quot;]\u0026quot; body: POST body timeout: Request timeout, unit seconds expectCode: Expect response code, such as 200,206 expectBody: Expect response body, support regexp, such as /success/ debug: Debug option, will log everything when this option is not empty Example { \u0026#34;executor\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://example.\n  Shell Executor  Shell executor run a system command Configuration Params shell: Run this command using a shell environment command: The command to run env: Env vars separated by comma cwd: Chdir before command run Example { \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;shell\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;my_command\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENV_VAR=va1,ANOTHER_ENV_VAR=var2\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;/app\u0026#34; } }\n  Processors Execution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it\u0026rsquo;s very flexible and per Job, examples of operations this plugins can do: Execution output storage, forwarding or redirection. Notification Monitoring For example, Processor plugins can be used to redirect the output of a job execution to different targets.\n  File Processor  File processor saves the execution output to a single log file in the specified directory Configuration Parameters log_dir: Path to the location where the log files will be saved forward: Forward log output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello files\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;files\u0026#34;: { \u0026#34;log_dir\u0026#34;: \u0026#34;/var/log/mydir\u0026#34;, \u0026#34;forward\u0026#34;: true } } }\n  Log Processor  Log processor writes the execution output to stdout/stderr Configuration Parameters forward: Forward the output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello log\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;log\u0026#34;: { \u0026#34;forward\u0026#34;: true } } }\n  Syslog Processor  Syslog processor writes the execution output to the system syslog daemon Note: Only work on linux systems Configuration Parameters forward: Forward the output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello syslog\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;syslog\u0026#34;: { \u0026#34;forward\u0026#34;: true } } }\n  Clustering Configure a cluster Dkron can run in HA mode, avoiding SPOFs, this mode provides better scalability and better reliability for users that wants a high level of confidence in the cron jobs they need to run. To form a cluster, server nodes need to know the address of its peers as in the following example: # dkron.yml join: - 10.19.3.9 - 10.19.4.64 - 10.19.7.215 Etcd For a more in detail guide of clustering with etcd follow this guide: https://github.\n  Concurrency  Concurrency Jobs can be configured to allow overlapping executions or forbid them. Concurrency property accepts two option: allow (default): Allow concurrent job executions. forbid: If the job is already running don\u0026rsquo;t send the execution, it will skip the executions until the next schedule. Example: { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;forbid\u0026#34; }\n  Internals This document is a WIP, it\u0026rsquo;s intended to describe the reasons that lead to design decisions in Dkron. Execution results Dkron store the result of each job execution in each node. Every time dkron executes a job it assigns it an execution group, generating a new uuid and send a serf query to target machines and waits for a response. Each target machine that will run the job, then responds with an execution object saying it started to run the job.\n  Job chaining Job chaining You can set some jobs to run after other job is executed. To setup a job that will be executed after any other given job, just set the parent_job property when saving the new job. The dependent job will be executed after the main job finished a successful execution. Child jobs schedule property will be ignored if it\u0026rsquo;s present. Take into account that parent jobs must be created before any child job.\n  Job retries Jobs can be configured to retry in case of failure. Configuration { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;retries\u0026#34;: 5 } In case of failure to run the job in one node, it will try to run the job again in that node until the retries count reaches the limit.\n  Metrics Dkron has the ability to send metrics to Statsd for dashboards and historical reporting. It sends job processing metrics and golang, serf metrics too. Configuration Add this in your yaml config file dog_statsd_addr: \u0026#34;localhost:8125\u0026#34; Metrics dkron.agent.event_received.query_execution_done dkron.agent.event_received.query_run_job dkron.memberlist.gossip dkron.memberlist.probeNode dkron.memberlist.pushPullNode dkron.memberlist.tcp.accept dkron.memberlist.tcp.connect dkron.memberlist.tcp.sent dkron.memberlist.udp.received dkron.memberlist.udp.sent dkron.grpc.call_execution_done dkron.grpc.call_get_job dkron.grpc.execution_done dkron.grpc.get_job dkron.runtime.alloc_bytes dkron.runtime.free_count dkron.runtime.gc_pause_ns dkron.runtime.heap_objects dkron.runtime.malloc_count dkron.runtime.num_goroutines dkron.runtime.sys_bytes dkron.runtime.total_gc_pause_ns dkron.runtime.total_gc_runs dkron.serf.coordinate.adjustment_ms dkron.serf.msgs.received dkron.serf.msgs.sent dkron.serf.queries dkron.serf.queries.execution_done dkron.serf.queries.run_job dkron.serf.query_acks dkron.serf.query_responses dkron.serf.queue.Event dkron.serf.queue.Intent dkron.\n  Plugins Intro Plugins in Dkron allow you to add funcionality that integrates with the workflow of the job execution in Dkron. It\u0026rsquo;s a powerful system that allows you to extend and adapt Dkron to your special needs. This page documents the basics of how the plugin system in Dkron works, and how to setup a basic development environment for plugin development if you\u0026rsquo;re writing a Dkron plugin. How it Works Dkron execution execution processors are provided via plugins.\n  Developing plugins Developing a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don\u0026rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation. Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language. Note: A common pitfall is not properly setting up a $GOPATH.\n  Use with AWS ECS Dkron Pro comes with a native ECS executor out of the box. Use with Amazon ECS To use Dkron to schedule jobs that run in containers, a wrapper ECS script is needed. Install the following snippet in the node that will run the call to ECS Prerequisites The node that will run the call to ECS will need to have installed AWS cli jq Example ecs-run --cluster cron --task-definition cron-taskdef --container-name cron --region us-east-1 --command \u0026quot;rake foo\u0026quot;\n  "
},
{
	"uri": "/pro/",
	"title": "Dkron Pro",
	"tags": [],
	"description": "",
	"content": "  Quick start Getting started Dkron Pro provides a clustering backend store out of the box based on etcd. To configure the storage a sample etcd.conf.yaml file is provided in /etc/dkron path. Editing the file, allows to configure several options for the embedded store. The location of the store configuration can be set in the command line or in the dkron config file /etc/dkron/dkron.yml using etcd-config-file-path parameter. Starting a single node Works out of the box, good for non HA installations.\n  Pro CLI dkron dkron Professional distributed job scheduling system Synopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention. Options --config string config file (default is /etc/dkron/dkron.yml) -h, --help help for dkron SEE ALSO dkron agent - Start a dkron agent dkron doc - Generate Markdown documentation for the Dkron CLI.\n  Authorization Dkron Pro has the ability to be configured to use HTTP basic auth. Authentication can be set using these parameters in the dkron config file: # dkron.yml username: dkron_admin password: adminpassword This will enable auth on the WebUI and for the API.\n  Clustering Configure a cluster First follow the Dkron clustering guide then you can continue with this guide. The embedded store also needs to know its peers, it needs its own configuration as in the following example: # etcd.conf.yaml # Initial cluster configuration for bootstrapping. initial-cluster: dkron1=https://10.19.3.9:2380,dkron2=https://10.19.4.64:2380,dkron3=https://10.19.7.215:2380 With this configuration Dkron Pro should start in cluster mode with embedded storage. For a more in detail guide of clustering with etcd follow this guide: https://github.\n  Commercial FAQ What is Dkron Pro? Dkron Pro is a flavor of Dkron which add more functionality and provide additional support options for customers. Is there a trial version? There\u0026rsquo;s no free trial but we do offer a 14 day period with full refund if it does not work for you. Can I get a discount? I\u0026rsquo;m sure you\u0026rsquo;re very nice but no. Everyone pays the same price. What is the license?\n  Commercial Support Dkron offers only community support. Dkro Pro offers priority support via email. Priority Support Covers 1 incident per quarter, with a max response time of 2 working days. Scope is limited to Dkron and Dkron Pro features and APIs, not the application or infrastructure. For support, email support AT distrib.works. Please email using the same domain as the original license email or explain your connection to the licensed company.\n  Configuration  Configuration Dkron Pro uses the same parameters as Dkron OSS and add some extra parameters. Command line options --etcd-config-file-path - Etcd node config --username - Authentication username --password - Authentication password --cert-file - Path to the client server TLS cert file --key-file - Path to the client server TLS key file --client-crl-file - Path to the client certificate revocation list file --trusted-ca-file - Path to the client server TLS trusted CA cert file --client-cert-auth - Enable client cert authentication --auto-tls - Client TLS using generated certificates   Embedded storage Dkron Pro has an embedded distributed KV store engine based on etcd. This works out of the box on each node dkron server is started. This ensures a dead easy install and setup, basically run dkron and you will have a full working node and at the same time provides you with a fully tested well supported store for its use with dkron.\n  Encryption SSL encryption is used for communicating dkron pro and the embedded store, and between storage nodes itself. Also if client auth is enabled, only dkron pro clients can talk to the embedded store. This means that no other software running on your local network will be able to talk to dkron\u0026rsquo;s etcd server. This ensures that no unexpected usage of the Dkron\u0026rsquo;s store will happen, unless it is another Dkron pro instance.\n  Executors \n  Processors Elasticsearch processor The Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node. The output logs of the job execution will be stored in the indicated ES instace. Configuration { \u0026#34;processors\u0026#34;: { \u0026#34;elasticsearch\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026#34;index\u0026#34;: \u0026#34;dkron_logs\u0026#34;, //desired index name (default: dkron_logs) \u0026#34;forward\u0026#34;: \u0026#34;false\u0026#34; //forward logs to the next processor (default: false) } } }\n  "
},
{
	"uri": "/products/",
	"title": "Products",
	"tags": [],
	"description": "",
	"content": "  Dkron Pro Dkron Pro Improved security, features and reliability for your scheduled jobs Buy Get additional fetures and commercial support from the creator of Dkron Key features Embedded storage When it comes to choose a storage you could be making a wrong decission. Easy of use comes from having a well tested and supported storage. The embedded etcd storage is tuned for use with dkron out of the box.\n  "
},
{
	"uri": "/intro/",
	"title": "Intro",
	"tags": [],
	"description": "",
	"content": " Dkron - Distributed, fault tolerant job scheduling system Welcome to the Dkron documentation! This is the reference guide on how to use Dkron. If you want a getting started guide refer to the getting started guide.\nWhat is Dkron Dkron is a distributed system to run scheduled jobs against a server or a group of servers of any size. One of the machines is the leader and the others will be followers. If the leader fails or becomes unreachable, any other one will take over and reschedule all jobs to keep the system healthy.\nIn case the old leader becomes alive again, it\u0026rsquo;ll become a follower.\nDkron is a distributed cron drop-in replacement, easy to setup and fault tolerant with focus in:\n Easy: Easy to use with a great UI Reliable: Completely fault tolerant High scalable: Able to handle high volumes of scheduled jobs and thousands of nodes  Dkron is written in Go and leverage the power of distributed key value stores and Serf for providing fault tolerance, reliability and scalability while keeping simple and easily installable.\nDkron is inspired by the google whitepaper Reliable Cron across the Planet\nDkron runs on Linux, OSX and Windows. It can be used to run scheduled commands on a server cluster using any combination of servers for each job. It has no single points of failure due to the use of the fault tolerant distributed databases and can work at large scale thanks to the efficient and lightweight gossip protocol.\nDkron uses the efficient and lightweight gossip protocol underneath to communicate with nodes. Failure notification and task handling are run efficiently across an entire cluster of any size.\nWeb UI \nDkron design Dkron is designed to solve one problem well, executing commands in given intervals. Following the unix philosophy of doing one thing and doing it well (like the battle-tested cron) but with the given addition of being designed for the cloud era, removing single points of failure in environments where scheduled jobs are needed to be run in multiple servers.\n"
},
{
	"uri": "/cli/",
	"title": "CLI",
	"tags": [],
	"description": "",
	"content": "  dkron dkron Open source distributed job scheduling system Synopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention. Options --config string config file path -h, --help help for dkron SEE ALSO dkron agent - Start a dkron agent dkron doc - Generate Markdown documentation for the Dkron CLI.\n  dkron agent dkron agent Start a dkron agent Synopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI. dkron agent [flags] Options --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. --advertise-rpc-port int Use the value of rpc-port by default. --backend string store backend (default \u0026quot;boltdb\u0026quot;) --backend-machine strings store backend machines addresses (default [.\n  dkron doc  dkron doc Generate Markdown documentation for the Dkron CLI. Synopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo. dkron doc [flags] Options --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands --config string config file path SEE ALSO dkron - Open source distributed job scheduling system Auto generated by spf13/cobra on 26-Nov-2018   dkron keygen  dkron keygen Generates a new encryption key Synopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects. dkron keygen [flags] Options -h, --help help for keygen Options inherited from parent commands --config string config file path SEE ALSO dkron - Open source distributed job scheduling system Auto generated by spf13/cobra on 26-Nov-2018   dkron version  dkron version Show version Synopsis Show the version dkron version [flags] Options -h, --help help for version Options inherited from parent commands --config string config file path SEE ALSO dkron - Open source distributed job scheduling system Auto generated by spf13/cobra on 26-Nov-2018   "
},
{
	"uri": "/pro/cli/",
	"title": "Pro CLI",
	"tags": [],
	"description": "",
	"content": "  dkron dkron Professional distributed job scheduling system Synopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention. Options --config string config file (default is /etc/dkron/dkron.yml) -h, --help help for dkron SEE ALSO dkron agent - Start a dkron agent dkron doc - Generate Markdown documentation for the Dkron CLI.\n  dkron agent dkron agent Start a dkron agent Synopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI. dkron agent [flags] Options --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. --advertise-rpc-port int Use the value of rpc-port by default. --auto-tls Client TLS using generated certificates (default true) --backend string store backend (default \u0026quot;boltdb\u0026quot;) --backend-machine strings store backend machines addresses (default [.\n  dkron doc dkron doc Generate Markdown documentation for the Dkron CLI. Synopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo. dkron doc [flags] Options --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.\n  dkron keygen  dkron keygen Generates a new encryption key Synopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects. dkron keygen [flags] Options -h, --help help for keygen Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO dkron - Professional distributed job scheduling system Auto generated by spf13/cobra on 21-Jan-2019   dkron version  dkron version Show version Synopsis Show the version dkron version [flags] Options -h, --help help for version Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO dkron - Professional distributed job scheduling system Auto generated by spf13/cobra on 21-Jan-2019   "
},
{
	"uri": "/usage/plugins/develop/",
	"title": "Developing plugins",
	"tags": [],
	"description": "",
	"content": " Developing a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don\u0026rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation. Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language.\nNote: A common pitfall is not properly setting up a $GOPATH. This can lead to strange errors. You can read more about this here to familiarize yourself.\nCreate a new Go project somewhere in your $GOPATH. If you\u0026rsquo;re a GitHub user, we recommend creating the project in the directory $GOPATH/src/github.com/USERNAME/dkron-NAME-TYPE, where USERNAME is your GitHub username and NAME is the name of the plugin you\u0026rsquo;re developing. This structure is what Go expects and simplifies things down the road.\nWith the directory made, create a main.go file. This project will be a binary so the package is \u0026ldquo;main\u0026rdquo;:\npackage main import ( \u0026#34;github.com/victorcoder/dkron/plugin\u0026#34; ) func main() { plugin.Serve(\u0026amp;plugin.ServeOpts{ Processor: new(MyPlugin), }) } And that\u0026rsquo;s basically it! You\u0026rsquo;ll have to change the argument given to plugin.Serve to be your actual plugin, but that is the only change you\u0026rsquo;ll have to make. The argument should be a structure implementing one of the plugin interfaces (depending on what sort of plugin you\u0026rsquo;re creating).\nDkron plugins must follow a very specific naming convention of dkron-TYPE-NAME. For example, dkron-processor-files, which tells Dkron that the plugin is a processor that can be referenced as \u0026ldquo;files\u0026rdquo;.\n"
},
{
	"uri": "/api/",
	"title": "API",
	"tags": [],
	"description": "",
	"content": " body { line-height: 1.7; } .swagger-ui .info .title small pre { background-color: inherit; padding: inherit; } .swagger-ui .scheme-container { display: none !important; } \n    window.onload = function () { // Begin Swagger UI call region const ui = SwaggerUIBundle({ url: \"https://dkron.io/swagger.yaml\", dom_id: '#swagger-ui', deepLinking: true, presets: [ SwaggerUIBundle.presets.apis, SwaggerUIStandalonePreset ], plugins: [ SwaggerUIBundle.plugins.DownloadUrl ], layout: \"BaseLayout\" }) // End Swagger UI call region window.ui = ui }  "
},
{
	"uri": "/cli/dkron/",
	"title": "dkron",
	"tags": [],
	"description": "",
	"content": " dkron Professional distributed job scheduling system\nSynopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention.\nOptions  --config string config file (default is /etc/dkron/dkron.yml) -h, --help help for dkron  SEE ALSO  dkron agent - Start a dkron agent dkron doc - Generate Markdown documentation for the Dkron CLI. dkron keygen - Generates a new encryption key dkron version - Show version  Auto generated by spf13/cobra on 21-Jan-2019 "
},
{
	"uri": "/cli/dkron_agent/",
	"title": "dkron agent",
	"tags": [],
	"description": "",
	"content": " dkron agent Start a dkron agent\nSynopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI.\ndkron agent [flags]  Options  --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. --advertise-rpc-port int Use the value of rpc-port by default. --auto-tls Client TLS using generated certificates (default true) --backend string store backend (default \u0026quot;boltdb\u0026quot;) --backend-machine strings store backend machines addresses (default [./dkron.db]) --bind-addr string Address to bind network listeners to. (default \u0026quot;0.0.0.0:8946\u0026quot;) --cert-file string Path to the client server TLS cert file --client-cert-auth Enable client cert authentication --client-crl-file string Path to the client certificate revocation list file --dog-statsd-addr string DataDog Agent address. --dog-statsd-tags strings Datadog tags, specified as key:value --encrypt string Key for encrypting network traffic. Must be a base64-encoded 16-byte key. --etcd-config-file-path string etcd node config (default \u0026quot;/etc/dkron/etcd.conf.yml\u0026quot;) -h, --help help for agent --http-addr string Address to bind the UI web server to. Only used when server. (default \u0026quot;:8080\u0026quot;) --join strings An initial agent to join with. This flag can be specified multiple times. --key-file string Path to the client server TLS key file --keyspace string The keyspace to use. A prefix under all data is stored for this instance. (default \u0026quot;dkron\u0026quot;) --log-level string Log level (debug, info, warn, error, fatal, panic), defaults to info (default \u0026quot;info\u0026quot;) --mail-from string From email address to use. --mail-host string Mail server host address to use for notifications. --mail-password string Mail server password to use. --mail-payload string Notification mail payload. --mail-port uint16 Mail server port. --mail-subject-prefix string Notification mail subject prefix. (default \u0026quot;[Dkron]\u0026quot;) --mail-username string Mail server username used for authentication. --node-name string Name of this node. Must be unique in the cluster. (default \u0026quot;pris.local\u0026quot;) --password string authentication password --profile string Profile is used to control the timing profiles used. The default if not provided is lan. (default \u0026quot;lan\u0026quot;) --rpc-port int RPC Port used to communicate with clients. Only used when server. The RPC IP Address will be the same as the bind address. (default 6868) --server This node is running in server mode. --statsd-addr string Statsd Address. --tag strings Tag can be specified multiple times to attach multiple key/value tag pairs to the given node. Specified as key=value --trusted-ca-file string Path to the client server TLS trusted CA cert file --username string authentication username --webhook-header strings Headers to use when calling the webhook URL. Can be specified multiple times. --webhook-payload string Body of the POST request to send on webhook call. --webhook-url string Webhook url to call for notifications.  Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml)  SEE ALSO  dkron - Professional distributed job scheduling system  Auto generated by spf13/cobra on 21-Jan-2019 "
},
{
	"uri": "/cli/dkron_doc/",
	"title": "dkron doc",
	"tags": [],
	"description": "",
	"content": " dkron doc Generate Markdown documentation for the Dkron CLI.\nSynopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo.\ndkron doc [flags]  Options  --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc  Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml)  SEE ALSO  dkron - Professional distributed job scheduling system  Auto generated by spf13/cobra on 21-Jan-2019 "
},
{
	"uri": "/cli/dkron_keygen/",
	"title": "dkron keygen",
	"tags": [],
	"description": "",
	"content": " dkron keygen Generates a new encryption key\nSynopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects.\ndkron keygen [flags]  Options  -h, --help help for keygen  Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml)  SEE ALSO  dkron - Professional distributed job scheduling system  Auto generated by spf13/cobra on 21-Jan-2019 "
},
{
	"uri": "/cli/dkron_version/",
	"title": "dkron version",
	"tags": [],
	"description": "",
	"content": " dkron version Show version\nSynopsis Show the version\ndkron version [flags]  Options  -h, --help help for version  Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml)  SEE ALSO  dkron - Professional distributed job scheduling system  Auto generated by spf13/cobra on 21-Jan-2019 "
},
{
	"uri": "/cli/dkron/",
	"title": "dkron",
	"tags": [],
	"description": "",
	"content": " dkron Open source distributed job scheduling system\nSynopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention.\nOptions  --config string config file path -h, --help help for dkron  SEE ALSO  dkron agent - Start a dkron agent dkron doc - Generate Markdown documentation for the Dkron CLI. dkron keygen - Generates a new encryption key dkron version - Show version  Auto generated by spf13/cobra on 26-Nov-2018 "
},
{
	"uri": "/cli/dkron_agent/",
	"title": "dkron agent",
	"tags": [],
	"description": "",
	"content": " dkron agent Start a dkron agent\nSynopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI.\ndkron agent [flags]  Options  --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. --advertise-rpc-port int Use the value of rpc-port by default. --backend string store backend (default \u0026quot;boltdb\u0026quot;) --backend-machine strings store backend machines addresses (default [./dkron.db]) --bind-addr string Address to bind network listeners to. (default \u0026quot;0.0.0.0:8946\u0026quot;) --dog-statsd-addr string DataDog Agent address. --dog-statsd-tags strings Datadog tags, specified as key:value --encrypt string Key for encrypting network traffic. Must be a base64-encoded 16-byte key. -h, --help help for agent --http-addr string Address to bind the UI web server to. Only used when server. (default \u0026quot;:8080\u0026quot;) --join strings An initial agent to join with. This flag can be specified multiple times. --keyspace string The keyspace to use. A prefix under all data is stored for this instance. (default \u0026quot;dkron\u0026quot;) --log-level string Log level (debug, info, warn, error, fatal, panic), defaults to info (default \u0026quot;info\u0026quot;) --mail-from string From email address to use. --mail-host string Mail server host address to use for notifications. --mail-password string Mail server password to use. --mail-payload string Notification mail payload. --mail-port string Mail server port. --mail-subject-prefix string Notification mail subject prefix. (default \u0026quot;[Dkron]\u0026quot;) --mail-username string Mail server username used for authentication. --node-name string Name of this node. Must be unique in the cluster. (default \u0026quot;pris.local\u0026quot;) --profile string Profile is used to control the timing profiles used. The default if not provided is lan. (default \u0026quot;lan\u0026quot;) --rpc-port int RPC Port used to communicate with clients. Only used when server. The RPC IP Address will be the same as the bind address. (default 6868) --server This node is running in server mode. --statsd-addr string Statsd Address. --tag strings Tag can be specified multiple times to attach multiple key/value tag pairs to the given node. Specified as key=value --webhook-header strings Headers to use when calling the webhook URL. Can be specified multiple times. --webhook-payload string Body of the POST request to send on webhook call. --webhook-url string Webhook url to call for notifications.  Options inherited from parent commands  --config string config file path  SEE ALSO  dkron - Open source distributed job scheduling system  Auto generated by spf13/cobra on 26-Nov-2018 "
},
{
	"uri": "/cli/dkron_doc/",
	"title": "dkron doc",
	"tags": [],
	"description": "",
	"content": " dkron doc Generate Markdown documentation for the Dkron CLI.\nSynopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo.\ndkron doc [flags]  Options  --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc  Options inherited from parent commands  --config string config file path  SEE ALSO  dkron - Open source distributed job scheduling system  Auto generated by spf13/cobra on 26-Nov-2018 "
},
{
	"uri": "/cli/dkron_keygen/",
	"title": "dkron keygen",
	"tags": [],
	"description": "",
	"content": " dkron keygen Generates a new encryption key\nSynopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects.\ndkron keygen [flags]  Options  -h, --help help for keygen  Options inherited from parent commands  --config string config file path  SEE ALSO  dkron - Open source distributed job scheduling system  Auto generated by spf13/cobra on 26-Nov-2018 "
},
{
	"uri": "/cli/dkron_version/",
	"title": "dkron version",
	"tags": [],
	"description": "",
	"content": " dkron version Show version\nSynopsis Show the version\ndkron version [flags]  Options  -h, --help help for version  Options inherited from parent commands  --config string config file path  SEE ALSO  dkron - Open source distributed job scheduling system  Auto generated by spf13/cobra on 26-Nov-2018 "
},
{
	"uri": "/_header/",
	"title": "header",
	"tags": [],
	"description": "",
	"content": "Dkron  "
},
{
	"uri": "/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Distributed Works © 2015 Victor Castell - victor@distrib.works\n"
},
{
	"uri": "/pro/executors/ecs/",
	"title": "AWS ECS Executor",
	"tags": [],
	"description": "",
	"content": "The ECS exeutor is capable of launching tasks in ECS clusters, then listen to a stream of CloudWatch Logs and return the output.\nTo configure a job to be run in ECS, the executor needs a JSON Task definition template or an already defined task in ECS.\nTo allow the ECS Task runner to run tasks, the machine running Dkron needs to have the appropriate permissions configured in AWS IAM:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1460720941000\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecs:RunTask\u0026#34;, \u0026#34;ecs:DescribeTasks\u0026#34;, \u0026#34;ecs:DescribeTaskDefinition\u0026#34;, \u0026#34;logs:FilterLogEvents\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] } ] } To configure a job to be run with the ECS executor:\nExample using an existing taskdef\n{ \u0026#34;executor\u0026#34;: \u0026#34;ecs\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;taskdefName\u0026#34;: \u0026#34;mytaskdef-family\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;eu-west-1\u0026#34;, \u0026#34;cluster\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;mycontainer\u0026#34;, \u0026#34;overrides\u0026#34;: \u0026#34;echo,\\\u0026#34;Hello from dkron\\\u0026#34;\u0026#34; } } Example using a provided taskdef\n{ \u0026#34;executor\u0026#34;: \u0026#34;ecs\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;taskdefBody\u0026#34;: \u0026#34;{\\\u0026#34;containerDefinitions\\\u0026#34;: [{\\\u0026#34;essential\\\u0026#34;: true,\\\u0026#34;image\\\u0026#34;: \\\u0026#34;hello-world\\\u0026#34;,\\\u0026#34;memory\\\u0026#34;: 100,\\\u0026#34;name\\\u0026#34;: \\\u0026#34;hello-world\\\u0026#34;}],\\\u0026#34;family\\\u0026#34;: \\\u0026#34;helloworld\\\u0026#34;}\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;eu-west-1\u0026#34;, \u0026#34;cluster\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;fargate\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34;, \u0026#34;maxAttempts\u0026#34;: 5000 } } This is the complete list of configuration parameters of the plugin:\ntaskdefBody taskdefName region cluster logGroup fargate securityGroup subnet env service overrides maxAttempts // Defaults to 2000, with 6s delay between it will wait up to 600s  "
},
{
	"uri": "/pro/auth/",
	"title": "Authorization",
	"tags": [],
	"description": "",
	"content": "Dkron Pro has the ability to be configured to use HTTP basic auth.\nAuthentication can be set using these parameters in the dkron config file:\n# dkron.yml username: dkron_admin password: adminpassword This will enable auth on the WebUI and for the API.\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/pro/clustering/",
	"title": "Clustering",
	"tags": [],
	"description": "",
	"content": " Configure a cluster First follow the Dkron clustering guide then you can continue with this guide.\nThe embedded store also needs to know its peers, it needs its own configuration as in the following example:\n# etcd.conf.yaml # Initial cluster configuration for bootstrapping. initial-cluster: dkron1=https://10.19.3.9:2380,dkron2=https://10.19.4.64:2380,dkron3=https://10.19.7.215:2380 With this configuration Dkron Pro should start in cluster mode with embedded storage.\nFor a more in detail guide of clustering with etcd follow this guide: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/clustering.md\n"
},
{
	"uri": "/usage/clustering/",
	"title": "Clustering",
	"tags": [],
	"description": "",
	"content": " Configure a cluster Dkron can run in HA mode, avoiding SPOFs, this mode provides better scalability and better reliability for users that wants a high level of confidence in the cron jobs they need to run.\nTo form a cluster, server nodes need to know the address of its peers as in the following example:\n# dkron.yml join: - 10.19.3.9 - 10.19.4.64 - 10.19.7.215 Etcd For a more in detail guide of clustering with etcd follow this guide: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/clustering.md\n"
},
{
	"uri": "/pro/commercial-faq/",
	"title": "Commercial FAQ",
	"tags": [],
	"description": "",
	"content": " What is Dkron Pro? Dkron Pro is a flavor of Dkron which add more functionality and provide additional support options for customers.\nIs there a trial version? There\u0026rsquo;s no free trial but we do offer a 14 day period with full refund if it does not work for you.\nCan I get a discount? I\u0026rsquo;m sure you\u0026rsquo;re very nice but no. Everyone pays the same price.\nWhat is the license? See COMM-LICENSE.\nHow does Pro licensing work? Every organization running Dkron Pro on its own servers must have a license. There\u0026rsquo;s no limit to the number of servers or environments used by that organization.\nWhat happens if my subscription lapses? You must have an active subscription to run Dkron Pro. After a one week grace period, you\u0026rsquo;ll lose access to the package repository and priority support. You won\u0026rsquo;t get any more updates or bug fixes and \u0026lsquo;apt-get install dkron-pro\u0026rsquo; won\u0026rsquo;t work anymore.\nCan I distribute Dkron Pro to my customers? This is a common requirement for \u0026ldquo;on-site installs\u0026rdquo; or \u0026ldquo;appliances\u0026rdquo; sold to large corporations.\nThe standard license is only appropriate for SaaS usage as it does not allow distribution. Dkron Pro have an Appliance license option which does allow you to distribute them. The Appliance license is $3,950/yr for Pro. It allows you to distribute the Pro binaries as part of your application and each of your customers to run Dkron Pro as part of your application only. Email support\u0026#64;distrib.works to purchase.\nCan you transfer a license? Licenses are not transferrable to another company. We will transfer the license from a user-specific email to a group email address (e.g. john_smith@example.com -\u0026gt; tech@example.com) but only for the same domain. It is strongly recommended that you buy the license using a group email address so the license is not attached to any one employee\u0026rsquo;s email address.\nWhat does the license require me to do? Your purchase gets you unique access credentials for downloading the Pro packages. The license agreement requires you to keep these access credentials private. If we find your access credentials are ever publicized:\n We\u0026rsquo;ll send you a warning email with details. You need to remove the content and send a new email address so we can generate new credentials for you. The old credentials will stop working immediately so you\u0026rsquo;ll need to update your apps. If your credentials are publicized a second time, we reserve the right to permanently remove access (but won\u0026rsquo;t unless it\u0026rsquo;s really egregious - sloppy contractors happen).  Can I get a refund? Yes, up to two weeks after purchase. Let us know the reason and maybe we can help but either way it\u0026rsquo;s not a problem. Email support\u0026#64;distrib.works.\nHow do I update my credit card info? If you purchased Dkron Pro (settings) with a credit card, log into Gumroad with your email address, click the Settings, enter your card info and hit Save. Follow instructions in Gumroad docs https://help.gumroad.com/how-do-i-update-my-credit-card-information I can\u0026rsquo;t provide support for the Gumroad website and don\u0026rsquo;t have the ability to edit customer info - if you can\u0026rsquo;t log in or change your credit card, you can always let your current subscription expire and purchase a new subscription.\nCan I request a change to the license terms? Dkron Pro is sold as is, no change to terms.\nCan I pay via invoice and purchase order? Dkron Pro is credit card only, no exceptions.\nContact Info Distributed Works\nAll billing/support inquiries: support@distrib.works\nPhone: not available\n"
},
{
	"uri": "/pro/commercial-support/",
	"title": "Commercial Support",
	"tags": [],
	"description": "",
	"content": " Dkron offers only community support. Dkro Pro offers priority support via email.\nPriority Support Covers 1 incident per quarter, with a max response time of 2 working days. Scope is limited to Dkron and Dkron Pro features and APIs, not the application or infrastructure. For support, email support AT distrib.works. Please email using the same domain as the original license email or explain your connection to the licensed company.\n"
},
{
	"uri": "/usage/concurrency/",
	"title": "Concurrency",
	"tags": [],
	"description": "",
	"content": " Concurrency Jobs can be configured to allow overlapping executions or forbid them.\nConcurrency property accepts two option:\n allow (default): Allow concurrent job executions. forbid: If the job is already running don\u0026rsquo;t send the execution, it will skip the executions until the next schedule.  Example:\n{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;forbid\u0026#34; }"
},
{
	"uri": "/basics/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": " Configuration sources Settings can be specified in three ways (in order of precedence):\n Command line arguments. Environment variables starting with DKRON_ dkron.json config file  Config file example # Dkron example configuration file # backend: etcd # backend-machine: 127.0.0.1:2379 # server: false # log-level: debug # tags: # role: web # datacenter: east # keyspace: dkron # encrypt: a-valid-key-generated-with-dkron-keygen # join: # - 10.0.0.1 # - 10.0.0.2 # - 10.0.0.3 # webhook-url: https://hooks.slack.com/services/XXXXXX/XXXXXXX/XXXXXXXXXXXXXXXXXXXX # webhook-payload: \u0026#34;payload={\\\u0026#34;text\\\u0026#34;: \\\u0026#34;{{.Report}}\\\u0026#34;, \\\u0026#34;channel\\\u0026#34;: \\\u0026#34;#foo\\\u0026#34;}\u0026#34; # webhook-headers: Content-Type:application/x-www-form-urlencoded # mail-host: email-smtp.eu-west-1.amazonaws.com # mail-port: 25 # mail-username\u0026#34;: mailuser # mail-password\u0026#34;: mailpassword # mail-from\u0026#34;: cron@example.com # mail-subject_prefix: [Dkron] SEE ALSO  dkron agent - Start a dkron agent dkron doc - Generate Markdown documentation for the Dkron CLI. dkron keygen - Generates a new encryption key dkron version - Show version  "
},
{
	"uri": "/pro/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": " Configuration Dkron Pro uses the same parameters as Dkron OSS and add some extra parameters.\nCommand line options  --etcd-config-file-path - Etcd node config --username - Authentication username --password - Authentication password --cert-file - Path to the client server TLS cert file --key-file - Path to the client server TLS key file --client-crl-file - Path to the client certificate revocation list file --trusted-ca-file - Path to the client server TLS trusted CA cert file --client-cert-auth - Enable client cert authentication --auto-tls - Client TLS using generated certificates  "
},
{
	"uri": "/",
	"title": "Dkron - Distributed job scheduling system",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/products/pro/",
	"title": "Dkron Pro",
	"tags": [],
	"description": "",
	"content": " Dkron Pro Improved security, features and reliability for your scheduled jobs  Buy      Get additional fetures and commercial support from the creator of Dkron\n Key features Embedded storage  When it comes to choose a storage you could be making a wrong decission. Easy of use comes from having a well tested and supported storage.\nThe embedded etcd storage is tuned for use with dkron out of the box.\nSecurity  Pro has enhanced security using industry standard SSL encryption for communication between all components of the application, the embedded storage engine and nodes.\nYou can also enable basic authentication to restrict access to the WebUI and the API.\nPro plugins  Do you need to store job output in Elasticsearch? Do you need to run docker based jobs?\nDkron Pro adds some commercially supported plugins ready to cover your needs.\n    Product details FEATURES  Dkron Pro contains the following functionality:   Works out of the box with the embedded storage   Full SSL encryption   Elasticsearch processor   Docker executor   AWS ECS executor   Advandec email processor   WebUI and API authorization   DOCUMENTATION Detailed documentation about configuring and using each feature can be found in the Dkron docs site. Read the Commercial FAQ for further detail.\nSUPPORT Your subscription gives you priority email support for any issues which might arise.\nSales of Dkron Pro also benefit the community by ensuring that Dkron itself will remain well supported for the foreseeable future.\nINSTALLATION When you buy Dkron Pro, a custom URL associated with your email address will be sent to you. You use this URL to install the package corresponding to your architecture. You configure and use Dkron Pro exactly like you would Dkron.\nPro tip: use a mailing list for your email when purchasing to ensure you get critical email updates, even if employees leave the company.\nUPGRADES Dkron Pro will receive bug fixes and new functionality over time. All upgrades will be free to subscribers with a simple package upgrade. See the changelog for more detail.\nLICENSING Dkron is available under the terms of the GNU LGPLv3 license.\nIn addition to its useful functionality, buying Dkron Pro grants your organization a Dkron commercial license instead of the GNU LGPL, avoiding any legal issues your lawyers might raise. Please see the Commercial FAQ for further detail on licensing including options for distributing Dkron Pro with your own products.\n   "
},
{
	"uri": "/intro/dkron_vs_other_software/",
	"title": "Dkron vs. Other Software",
	"tags": [],
	"description": "",
	"content": " Dkron vs. Chronos Airbnb\u0026rsquo;s Chronos is a job scheduler that is similar to dkron, it\u0026rsquo;s distributed and fault tolerant thanks to the use of Zookeeper and Apache Mesos.\nIf you don\u0026rsquo;t have/want to run a Mesos cluster and deal with the not easy configuration and maintenance of Zookeeper and you want something lighter, Dkron could help you.\nDkron vs. Rundeck Rundeck is a popular and mature platform to automate operations and schedule jobs.\nIt has cool features:\n Agentless Permissions and auditing  It\u0026rsquo;s written in Java and it\u0026rsquo;s not trivial to setup right.\nIt uses a central database to store job execution results and configuration data, that makes it vulnerable to failures, and you need to care yourself of providing an HA environement for the database, and that\u0026rsquo;s not an easy task to do with the Rundeck\u0026rsquo;s supported databases.\nDkron lacks some of it\u0026rsquo;s features but it\u0026rsquo;s lightweight and fault-tolerant out-of-the-box.\n"
},
{
	"uri": "/pro/executors/docker/",
	"title": "Docker executor",
	"tags": [],
	"description": "",
	"content": " Docker executor can launch docker based cron jobs using the docker command of the target node.\nThis executor needs a recent version of docker to be available and configured in the target node.\nConfiguration To run a docker job create a job config with the docker executor as in this example:\n{ \u0026#34;executor\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;image\u0026#34;: \u0026#34;alpine\u0026#34;, //docker image to use \u0026#34;volumes\u0026#34;: \u0026#34;/logs:/var/log/\u0026#34;, //comma separated list of volume mappings \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from dkron\\\u0026#34;\u0026#34;, //command to pass to run on container \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34; //environment variables to pass to the container } }"
},
{
	"uri": "/pro/processors/elasticsearch/",
	"title": "Elasticsearch processor",
	"tags": [],
	"description": "",
	"content": " The Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node.\nThe output logs of the job execution will be stored in the indicated ES instace.\nConfiguration { \u0026#34;processors\u0026#34;: { \u0026#34;elasticsearch\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026#34;index\u0026#34;: \u0026#34;dkron_logs\u0026#34;, //desired index name (default: dkron_logs) \u0026#34;forward\u0026#34;: \u0026#34;false\u0026#34; //forward logs to the next processor (default: false) } } }"
},
{
	"uri": "/pro/processors/email/",
	"title": "Email processor",
	"tags": [],
	"description": "",
	"content": "The Email processor provides flexibility to job email notifications.\nConfiguration of the email processor is stored in a file named dkron-processor-email.yml in the same locations as dkron.yml, and should include a list of providers, it can include any number of providers.\nExample:\nprovider1: host: smtp.myprovider.com port: 25 username: myusername password: mypassword from: cron@mycompany.com subjectPrefix: \u0026#39;[Staging] \u0026#39; Then configure each job with the following options:\nExample:\n{ \u0026#34;processors\u0026#34;: { \u0026#34;email\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;provider1\u0026#34;, \u0026#34;emails\u0026#34;: \u0026#34;team@mycompany.com, owner@mycompany.com\u0026#34;, \u0026#34;onSuccess\u0026#34;: true } } } By default the email procesor doesn\u0026rsquo;t send emails on job success, the onSuccess parameter, enables it, like in the previous example.\n"
},
{
	"uri": "/pro/storage/",
	"title": "Embedded storage",
	"tags": [],
	"description": "",
	"content": "Dkron Pro has an embedded distributed KV store engine based on etcd. This works out of the box on each node dkron server is started.\nThis ensures a dead easy install and setup, basically run dkron and you will have a full working node and at the same time provides you with a fully tested well supported store for its use with dkron.\n"
},
{
	"uri": "/pro/encryption/",
	"title": "Encryption",
	"tags": [],
	"description": "",
	"content": "SSL encryption is used for communicating dkron pro and the embedded store, and between storage nodes itself. Also if client auth is enabled, only dkron pro clients can talk to the embedded store. This means that no other software running on your local network will be able to talk to dkron\u0026rsquo;s etcd server.\nThis ensures that no unexpected usage of the Dkron\u0026rsquo;s store will happen, unless it is another Dkron pro instance.\nSSL encryption is enabled by default in Dkron Pro and can not be disabled, you don\u0026rsquo;t need to do nothing to use it.\nBy default Dkron Pro runs with automatically generated SSL certificates, this is enough for using it in a trusted environment but to have a better grade of confidence, it is recommended to run Dkron Pro with custom SSL certificates.\nFollow this tutorial to generate autosigned SSL certificates for your instances.\nYou don\u0026rsquo;t need a client certificate for Dkron server, just add \u0026ldquo;client auth\u0026rdquo; usage to your server cert.\n # dkron.yaml auto-tls: false # Set to false to use custom certs key-file: server-key.pem cert-file: server.pem trusted-ca-file: ca.pem client-cert-auth: true # Enable it to only allow certs signed by the same CA"
},
{
	"uri": "/pro/executors/",
	"title": "Executors",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/usage/processors/file/",
	"title": "File Processor",
	"tags": [],
	"description": "",
	"content": " File processor saves the execution output to a single log file in the specified directory\nConfiguration Parameters\nlog_dir: Path to the location where the log files will be saved forward: Forward log output to the next processor  Example\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello files\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;files\u0026#34;: { \u0026#34;log_dir\u0026#34;: \u0026#34;/var/log/mydir\u0026#34;, \u0026#34;forward\u0026#34;: true } } }"
},
{
	"uri": "/usage/executors/http/",
	"title": "HTTP Executor",
	"tags": [],
	"description": "",
	"content": " HTTP executor can send a request to an HTTP endpoint\nConfiguration Params:\nmethod: Request method in uppercase url: Request url headers: Json string, such as \u0026quot;[\\\u0026quot;Content-Type: application/json\\\u0026quot;]\u0026quot; body: POST body timeout: Request timeout, unit seconds expectCode: Expect response code, such as 200,206 expectBody: Expect response body, support regexp, such as /success/ debug: Debug option, will log everything when this option is not empty  Example\n{ \u0026#34;executor\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://example.com\u0026#34;, \u0026#34;headers\u0026#34;: \u0026#34;[]\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;timeout\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;expectCode\u0026#34;: \u0026#34;200\u0026#34;, \u0026#34;expectBody\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;debug\u0026#34;: \u0026#34;true\u0026#34; } }"
},
{
	"uri": "/usage/internals/",
	"title": "Internals",
	"tags": [],
	"description": "",
	"content": " This document is a WIP, it\u0026rsquo;s intended to describe the reasons that lead to design decisions in Dkron.\nExecution results Dkron store the result of each job execution in each node.\nEvery time dkron executes a job it assigns it an execution group, generating a new uuid and send a serf query to target machines and waits for a response.\nEach target machine that will run the job, then responds with an execution object saying it started to run the job.\nThis allows dkron to know how many machines will be running the job.\nThe design takes into account the differences of how the different storage backends work.\nDue to this issue https://github.com/docker/libkv/issues/20 executions are grouped using the group id in the execution object.\nExecutions commands output When a node has finished executing a job it gathers the output of the executed command and sends it back to the a server using an RPC call. This is designed after two main reasons:\n Scallability, in case of thousands of nodes responding to job the responses are sent to dkron servers in an evenly way selecting a random Dkron server of the ones that are available at the moment and send the response. In the future, Dkron should retry sending the command result with an exponential backoff.\n Due to the limitations of Serf the queries payload can\u0026rsquo;t be bigger that 1KB, this renders impossible to send a minimal command output togheter with the execution metadata.\n  "
},
{
	"uri": "/usage/chaining/",
	"title": "Job chaining",
	"tags": [],
	"description": "",
	"content": " Job chaining You can set some jobs to run after other job is executed. To setup a job that will be executed after any other given job, just set the parent_job property when saving the new job.\nThe dependent job will be executed after the main job finished a successful execution.\nChild jobs schedule property will be ignored if it\u0026rsquo;s present.\nTake into account that parent jobs must be created before any child job.\nExample:\n{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; } } { \u0026#34;name\u0026#34;: \u0026#34;child_job\u0026#34;, \u0026#34;parent_job\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from child\\\u0026#34;\u0026#34; } }"
},
{
	"uri": "/usage/retries/",
	"title": "Job retries",
	"tags": [],
	"description": "",
	"content": " Jobs can be configured to retry in case of failure.\nConfiguration { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;retries\u0026#34;: 5 } In case of failure to run the job in one node, it will try to run the job again in that node until the retries count reaches the limit.\n"
},
{
	"uri": "/intro/license/",
	"title": "License",
	"tags": [],
	"description": "",
	"content": "Copyright \u0026copy; Victor Castell\nDkron is an Open Source project licensed under the terms of the LGPLv3 license. Please see http://www.gnu.org/licenses/lgpl-3.0.html for license text.\n"
},
{
	"uri": "/usage/processors/log/",
	"title": "Log Processor",
	"tags": [],
	"description": "",
	"content": " Log processor writes the execution output to stdout/stderr\nConfiguration Parameters\nforward: Forward the output to the next processor\nExample\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello log\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;log\u0026#34;: { \u0026#34;forward\u0026#34;: true } } }"
},
{
	"uri": "/usage/metrics/",
	"title": "Metrics",
	"tags": [],
	"description": "",
	"content": " Dkron has the ability to send metrics to Statsd for dashboards and historical reporting. It sends job processing metrics and golang, serf metrics too.\nConfiguration Add this in your yaml config file\ndog_statsd_addr: \u0026#34;localhost:8125\u0026#34; Metrics  dkron.agent.event_received.query_execution_done dkron.agent.event_received.query_run_job dkron.memberlist.gossip dkron.memberlist.probeNode dkron.memberlist.pushPullNode dkron.memberlist.tcp.accept dkron.memberlist.tcp.connect dkron.memberlist.tcp.sent dkron.memberlist.udp.received dkron.memberlist.udp.sent dkron.grpc.call_execution_done dkron.grpc.call_get_job dkron.grpc.execution_done dkron.grpc.get_job dkron.runtime.alloc_bytes dkron.runtime.free_count dkron.runtime.gc_pause_ns dkron.runtime.heap_objects dkron.runtime.malloc_count dkron.runtime.num_goroutines dkron.runtime.sys_bytes dkron.runtime.total_gc_pause_ns dkron.runtime.total_gc_runs dkron.serf.coordinate.adjustment_ms dkron.serf.msgs.received dkron.serf.msgs.sent dkron.serf.queries dkron.serf.queries.execution_done dkron.serf.queries.run_job dkron.serf.query_acks dkron.serf.query_responses dkron.serf.queue.Event dkron.serf.queue.Intent dkron.serf.queue.Query  "
},
{
	"uri": "/usage/plugins/",
	"title": "Plugins",
	"tags": [],
	"description": "",
	"content": " Intro Plugins in Dkron allow you to add funcionality that integrates with the workflow of the job execution in Dkron. It\u0026rsquo;s a powerful system that allows you to extend and adapt Dkron to your special needs.\nThis page documents the basics of how the plugin system in Dkron works, and how to setup a basic development environment for plugin development if you\u0026rsquo;re writing a Dkron plugin.\nHow it Works Dkron execution execution processors are provided via plugins. Each plugin exposes functionality for modifying the execution. Plugins are executed as a separate process and communicate with the main Dkron binary over an RPC interface.\nThe code within the binaries must adhere to certain interfaces. The network communication and RPC is handled automatically by higher-level libraries. The exact interface to implement is documented in its respective documentation section.\nInstalling a Plugin Dkron searches for plugins at startup, to install a plugin just drop the binary in one of the following locations:\n /etc/dkron/plugins Dkron executable directory   Developing plugins   "
},
{
	"uri": "/pro/processors/",
	"title": "Processors",
	"tags": [],
	"description": "",
	"content": "  Elasticsearch processor  The Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node. The output logs of the job execution will be stored in the indicated ES instace. Configuration { \u0026#34;processors\u0026#34;: { \u0026#34;elasticsearch\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026#34;index\u0026#34;: \u0026#34;dkron_logs\u0026#34;, //desired index name (default: dkron_logs) \u0026#34;forward\u0026#34;: \u0026#34;false\u0026#34; //forward logs to the next processor (default: false) } } }\n  Email processor The Email processor provides flexibility to job email notifications. Configuration of the email processor is stored in a file named dkron-processor-email.yml in the same locations as dkron.yml, and should include a list of providers, it can include any number of providers. Example: provider1: host: smtp.myprovider.com port: 25 username: myusername password: mypassword from: cron@mycompany.com subjectPrefix: \u0026#39;[Staging] \u0026#39; Then configure each job with the following options: Example: { \u0026#34;processors\u0026#34;: { \u0026#34;email\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;provider1\u0026#34;, \u0026#34;emails\u0026#34;: \u0026#34;team@mycompany.\n  Slack processor The Slack processor provides slack notifications with multiple configurations and rich format. Configuration of the slack processor is stored in a file named dkron-processor-slack.yml in the same locations as dkron.yml, and should include a list of teams, it can include any number of teams. Example: team1: webhook_url: https://hooks.slack.com/services/XXXXXXXXXXXXXXXXXXX bot_name: Dkron Production Then configure each job with the following options: Example: { \u0026#34;processors\u0026#34;: { \u0026#34;slack\u0026#34;: { \u0026#34;team\u0026#34;: \u0026#34;team1\u0026#34;, \u0026#34;channel\u0026#34;: \u0026#34;#cron-production\u0026#34;, \u0026#34;onSuccess\u0026#34;: true } } } By default the slack procesor doesn\u0026rsquo;t send notifications on job success, the onSuccess parameter, enables it, like in the previous example.\n  "
},
{
	"uri": "/usage/executors/shell/",
	"title": "Shell Executor",
	"tags": [],
	"description": "",
	"content": " Shell executor run a system command\nConfiguration Params\nshell: Run this command using a shell environment command: The command to run env: Env vars separated by comma cwd: Chdir before command run  Example\n{ \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;shell\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;my_command\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENV_VAR=va1,ANOTHER_ENV_VAR=var2\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;/app\u0026#34; } }"
},
{
	"uri": "/pro/processors/slack/",
	"title": "Slack processor",
	"tags": [],
	"description": "",
	"content": "The Slack processor provides slack notifications with multiple configurations and rich format.\nConfiguration of the slack processor is stored in a file named dkron-processor-slack.yml in the same locations as dkron.yml, and should include a list of teams, it can include any number of teams.\nExample:\nteam1: webhook_url: https://hooks.slack.com/services/XXXXXXXXXXXXXXXXXXX bot_name: Dkron Production Then configure each job with the following options:\nExample:\n{ \u0026#34;processors\u0026#34;: { \u0026#34;slack\u0026#34;: { \u0026#34;team\u0026#34;: \u0026#34;team1\u0026#34;, \u0026#34;channel\u0026#34;: \u0026#34;#cron-production\u0026#34;, \u0026#34;onSuccess\u0026#34;: true } } } By default the slack procesor doesn\u0026rsquo;t send notifications on job success, the onSuccess parameter, enables it, like in the previous example.\n"
},
{
	"uri": "/usage/processors/syslog/",
	"title": "Syslog Processor",
	"tags": [],
	"description": "",
	"content": " Syslog processor writes the execution output to the system syslog daemon\nNote: Only work on linux systems\nConfiguration Parameters\nforward: Forward the output to the next processor\nExample\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello syslog\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;syslog\u0026#34;: { \u0026#34;forward\u0026#34;: true } } }"
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/usage/ecs/",
	"title": "Use with AWS ECS",
	"tags": [],
	"description": "",
	"content": " Dkron Pro comes with a native ECS executor out of the box.\n Use with Amazon ECS To use Dkron to schedule jobs that run in containers, a wrapper ECS script is needed.\nInstall the following snippet in the node that will run the call to ECS\n Prerequisites The node that will run the call to ECS will need to have installed\n AWS cli jq  Example ecs-run --cluster cron --task-definition cron-taskdef --container-name cron --region us-east-1 --command \u0026quot;rake foo\u0026quot;\n"
}]