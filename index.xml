<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dkron - Distributed job scheduling system</title>
    <link>/</link>
    <description>Recent content on Dkron - Distributed job scheduling system</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Apr 2017 18:36:24 +0200</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Execution Processors</title>
      <link>/usage/plugins/processors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/plugins/processors/</guid>
      <description>Execution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it&amp;rsquo;s very flexible and per Job, examples of operations this plugins can do:
 Execution output storage, forwarding or redirection. Notification Monitoring  For example, Processor plugins can be used to redirect the output of a job execution to different targets.</description>
    </item>
    
    <item>
      <title>Executors</title>
      <link>/usage/plugins/executors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/plugins/executors/</guid>
      <description>Executors Executors plugins are the main mechanism of execution in Dkron. They implement different &amp;ldquo;types&amp;rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes.
For example, the built-in shell executor, will run the indicated command in the target node.
New plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.</description>
    </item>
    
    <item>
      <title>Installation</title>
      <link>/basics/installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/basics/installation/</guid>
      <description>Running the binary Download the packaged archive for your platform from the downloads page and extract the package to a shared location in your drive, like /opt/local/bin.
Run Dkron with default setting: dkron agent --server
Navigate to http://localhost:8080
By default dkron will start with a file based, embedded KV store called BoltDB, it is functional for a single node demo but does not offers clustering or HA.
 Installing the package Debian repo APT repository:</description>
    </item>
    
    <item>
      <title>Quick start</title>
      <link>/pro/quick-start/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/quick-start/</guid>
      <description>Getting started Dkron Pro provides a clustering backend store out of the box based on etcd.
To configure the storage a sample etcd.conf.yaml file is provided in /etc/dkron path. Editing the file, allows to configure several options for the embedded store.
The location of the store configuration can be set in the command line or in the dkron config file /etc/dkron/dkron.yml using etcd-config-file-path parameter.
Starting a single node Works out of the box, good for non HA installations.</description>
    </item>
    
    <item>
      <title>Target nodes spec</title>
      <link>/usage/target-nodes-spec/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/target-nodes-spec/</guid>
      <description>Target nodes spec You can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run.
The target node syntax: [tag-value]:[count]
 Examples: Target all nodes with a tag:
{ &amp;quot;name&amp;quot;: &amp;quot;job_name&amp;quot;, &amp;quot;command&amp;quot;: &amp;quot;/bin/true&amp;quot;, &amp;quot;schedule&amp;quot;: &amp;quot;@every 2m&amp;quot;, &amp;quot;tags&amp;quot;: { &amp;quot;role&amp;quot;: &amp;quot;web&amp;quot; } }  Target only two nodes of a group of nodes with a tag:</description>
    </item>
    
    <item>
      <title>Cron spec</title>
      <link>/usage/cron-spec/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/cron-spec/</guid>
      <description>CRON Expression Format A cron expression represents a set of times, using 6 space-separated fields.
Field name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ?</description>
    </item>
    
    <item>
      <title>Getting started</title>
      <link>/basics/getting-started/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/basics/getting-started/</guid>
      <description>Introduction Dkron nodes can work in two modes, agents or servers.
A Dkron agent is a cluster member that can handle job executions, run your scripts and return the resulting output to the server.
A Dkron server is also a cluster member that send job execution queries to agents or other servers, so servers can execute jobs too.
The main distinction is that servers order job executions, can be used to schedule jobs, handles data storage and participate on leader election.</description>
    </item>
    
    <item>
      <title>Developing plugins</title>
      <link>/usage/plugins/develop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/plugins/develop/</guid>
      <description>Developing a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don&amp;rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation. Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language.
Note: A common pitfall is not properly setting up a $GOPATH.</description>
    </item>
    
    <item>
      <title>header</title>
      <link>/_header/</link>
      <pubDate>Mon, 24 Apr 2017 18:36:24 +0200</pubDate>
      
      <guid>/_header/</guid>
      <description>Dkron  </description>
    </item>
    
    <item>
      <title></title>
      <link>/_footer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/_footer/</guid>
      <description>Distributed Works Â© 2015 Victor Castell - victor@distrib.works</description>
    </item>
    
    <item>
      <title>AWS ECS Executor</title>
      <link>/pro/ecs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/ecs/</guid>
      <description>The ECS exeutor is capable of launching tasks in ECS clusters, then listen to a stream of CloudWatch Logs and return the output.
To configure a job to be run in ECS, the executor needs a JSON Task definition template or an already defined task in ECS.
To allow the ECS Task runner to run tasks, the machine running Dkron needs to have the appropriate permissions configured in AWS IAM:</description>
    </item>
    
    <item>
      <title>Authorization</title>
      <link>/pro/auth/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/auth/</guid>
      <description>Dkron Pro has the ability to be configured to use HTTP basic auth.
Authentication can be set using these parameters in the dkron config file:
# dkron.yml username: foo password: bar This will enable auth on the WebUI and for the API.</description>
    </item>
    
    <item>
      <title>Clustering</title>
      <link>/pro/clustering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/clustering/</guid>
      <description>Configure a cluster First follow the Dkron clustering guide then you can continue with this guide.
The embedded store also needs to know its peers, it needs its own configuration as in the following example:
# etcd.conf.yaml # Initial cluster configuration for bootstrapping. initial-cluster: dkron1=https://10.19.3.9:2380,dkron2=https://10.19.4.64:2380,dkron3=https://10.19.7.215:2380 With this configuration Dkron Pro should start in cluster mode with embedded storage.
For a more in detail guide of clustering with etcd follow this guide: https://github.</description>
    </item>
    
    <item>
      <title>Clustering</title>
      <link>/usage/clustering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/clustering/</guid>
      <description>Configure a cluster Dkron can run in HA mode, avoiding SPOFs, this mode provides better scalability and better reliability for users that wants a high level of confidence in the cron jobs they need to run.
To form a cluster, server nodes need to know the address of its peers as in the following example:
# dkron.yml join: - 10.19.3.9 - 10.19.4.64 - 10.19.7.215 Etcd For a more in detail guide of clustering with etcd follow this guide: https://github.</description>
    </item>
    
    <item>
      <title>Commercial FAQ</title>
      <link>/pro/commercial-faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/commercial-faq/</guid>
      <description>What is Dkron Pro? Dkron Pro is a flavor of Dkron which add more functionality and provide additional support options for customers.
Is there a trial version? There&amp;rsquo;s no free trial but we do offer a 14 day period with full refund if it does not work for you.
Can I get a discount? I&amp;rsquo;m sure you&amp;rsquo;re very nice but no. Everyone pays the same price.
What is the license?</description>
    </item>
    
    <item>
      <title>Commercial Support</title>
      <link>/pro/commercial-support/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/commercial-support/</guid>
      <description>Dkron offers only community support. Dkro Pro offers priority support via email.
Priority Support Covers 1 incident per quarter, with a max response time of 2 working days. Scope is limited to Dkron and Dkron Pro features and APIs, not the application or infrastructure. For support, email support AT distrib.works. Please email using the same domain as the original license email or explain your connection to the licensed company.</description>
    </item>
    
    <item>
      <title>Concurrency</title>
      <link>/usage/concurrency/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/concurrency/</guid>
      <description> Concurrency Jobs can be configured to allow overlapping executions or forbid them.
Concurrency property accepts two option:
 allow (default): Allow concurrent job executions. forbid: If the job is already running don&amp;rsquo;t send the execution, it will skip the executions until the next schedule.  Example:
{ &amp;#34;name&amp;#34;: &amp;#34;job1&amp;#34;, &amp;#34;schedule&amp;#34;: &amp;#34;@every 10s&amp;#34;, &amp;#34;executor&amp;#34;: &amp;#34;shell&amp;#34;, &amp;#34;executor_config&amp;#34;: { &amp;#34;command&amp;#34;: &amp;#34;echo \&amp;#34;Hello from parent\&amp;#34;&amp;#34; }, &amp;#34;concurrency&amp;#34;: &amp;#34;forbid&amp;#34; }</description>
    </item>
    
    <item>
      <title>Configuration</title>
      <link>/basics/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/basics/configuration/</guid>
      <description>Settings for dkron can be specified in three ways: Using a config/dkron.json config file, using env variables starting with DKRON_ or using command line arguments.
Command line options  --node-name - Name of the node, must be unique in the cluster. By default this is the hostname of the machine.
 --bind-addr - The address that dkron will bind to for communication with other dkron nodes. By default this is &amp;ldquo;0.</description>
    </item>
    
    <item>
      <title>Configuration</title>
      <link>/pro/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/configuration/</guid>
      <description> Configuration Dkron Pro uses the same parameters as Dkron OSS and add some extra parameters.
Command line options  --etcd-config-file-path - Etcd node config --username - Authentication username --password - Authentication password --cert-file - Path to the client server TLS cert file --key-file - Path to the client server TLS key file --client-crl-file - Path to the client certificate revocation list file --trusted-ca-file - Path to the client server TLS trusted CA cert file --client-cert-auth - Enable client cert authentication --auto-tls - Client TLS using generated certificates  </description>
    </item>
    
    <item>
      <title>Dkron Pro</title>
      <link>/products/pro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/products/pro/</guid>
      <description>Dkron Pro Improved security, features and reliability for your scheduled jobs      Get additional fetures and commercial support from the creator of Dkron
 Key features Embedded storage  When it comes to choose a storage you could be making a wrong decission. Easy of use comes from having a well tested and supported storage.
The embedded etcd storage is tuned for use with dkron out of the box.</description>
    </item>
    
    <item>
      <title>Dkron vs. Other Software</title>
      <link>/intro/dkron_vs_other_software/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/intro/dkron_vs_other_software/</guid>
      <description>Dkron vs. Chronos Airbnb&amp;rsquo;s Chronos is a job scheduler that is similar to dkron, it&amp;rsquo;s distributed and fault tolerant thanks to the use of Zookeeper and Apache Mesos.
If you don&amp;rsquo;t have/want to run a Mesos cluster and deal with the not easy configuration and maintenance of Zookeeper and you want something lighter, Dkron could help you.
Dkron vs. Rundeck Rundeck is a popular and mature platform to automate operations and schedule jobs.</description>
    </item>
    
    <item>
      <title>Docker executor</title>
      <link>/pro/docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/docker/</guid>
      <description> Docker executor can launch docker based cron jobs using the docker command of the target node.
This executor needs a recent version of docker to be available and configured in the target node.
Configuration To run a docker job create a job config with the docker executor as in this example:
&amp;#34;executor&amp;#34;: &amp;#34;docker&amp;#34;, &amp;#34;executor_config&amp;#34;: { &amp;#34;image&amp;#34;: &amp;#34;alpine&amp;#34;, //docker image to use &amp;#34;volumes&amp;#34;: &amp;#34;/logs:/var/log/&amp;#34;, //comma separated list of volume mappings &amp;#34;command&amp;#34;: &amp;#34;echo \&amp;#34;Hello from dkron\&amp;#34;&amp;#34;, //command to pass to run on container &amp;#34;env&amp;#34;: &amp;#34;ENVIRONMENT=variable&amp;#34; //environment variables to pass to the container }</description>
    </item>
    
    <item>
      <title>Elasticsearch processor</title>
      <link>/pro/elasticsearch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/elasticsearch/</guid>
      <description> The Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node.
The output logs of the job execution will be stored in the indicated ES instace.
Configuration &amp;#34;processors&amp;#34;: { &amp;#34;elasticsearch&amp;#34;: { &amp;#34;url&amp;#34;: &amp;#34;http://localhost:9200&amp;#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) &amp;#34;index&amp;#34;: &amp;#34;dkron_logs&amp;#34;, //desired index name (default: dkron_logs) &amp;#34;forward&amp;#34;: &amp;#34;false&amp;#34; //forward logs to the next processor (default: false) } }</description>
    </item>
    
    <item>
      <title>Email processor</title>
      <link>/pro/email/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/email/</guid>
      <description>The Email processor provides flexibility to job email notifications.
Configuration of the email processor is stored in a file named dkron-processor-email.yml in the same locations as dkron.yml, and should include a list of providers, it can include any number of providers.
Example:
provider1: host: smtp.myprovider.com port: 25 username: myusername password: mypassword from: cron@mycompany.com subjectPrefix: &amp;#39;[Staging] &amp;#39; Then configure each job with the following options:
Example:
&amp;#34;processors&amp;#34;: { &amp;#34;email&amp;#34;: { &amp;#34;provider&amp;#34;: &amp;#34;provider1&amp;#34;, &amp;#34;emails&amp;#34;: &amp;#34;team@mycompany.</description>
    </item>
    
    <item>
      <title>Embedded storage</title>
      <link>/pro/storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/storage/</guid>
      <description>Dkron Pro has an embedded distributed KV store engine based on etcd. This works out of the box on each node dkron server is started.
This ensures a dead easy install and setup, basically run dkron and you will have a full working node and at the same time provides you with a fully tested well supported store for its use with dkron.</description>
    </item>
    
    <item>
      <title>Encryption</title>
      <link>/pro/encryption/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pro/encryption/</guid>
      <description>SSL encryption is used for communicating dkron pro and the embedded store, and between storage nodes itself. Also if client auth is enabled, only dkron pro clients can talk to the embedded store. This means that no other software running on your local network will be able to talk to dkron&amp;rsquo;s etcd server.
This ensures that no unexpected usage of the Dkron&amp;rsquo;s store will happen, unless it is another Dkron pro instance.</description>
    </item>
    
    <item>
      <title>Internals</title>
      <link>/usage/internals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/internals/</guid>
      <description>This document is a WIP, it&amp;rsquo;s intended to describe the reasons that lead to design decisions in Dkron.
Execution results Dkron store the result of each job execution in each node.
Every time dkron executes a job it assigns it an execution group, generating a new uuid and send a serf query to target machines and waits for a response.
Each target machine that will run the job, then responds with an execution object saying it started to run the job.</description>
    </item>
    
    <item>
      <title>Job chaining</title>
      <link>/usage/chaining/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/chaining/</guid>
      <description>Job chaining You can set some jobs to run after other job is executed. To setup a job that will be executed after any other given job, just set the parent_job property when saving the new job.
The dependent job will be executed after the main job finished a successful execution.
Child jobs schedule property will be ignored if it&amp;rsquo;s present.
Take into account that parent jobs must be created before any child job.</description>
    </item>
    
    <item>
      <title>Job retries</title>
      <link>/usage/retries/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/retries/</guid>
      <description>Jobs can be configured to retry in case of failure.
Configuration { &amp;#34;name&amp;#34;: &amp;#34;job1&amp;#34;, &amp;#34;schedule&amp;#34;: &amp;#34;@every 10s&amp;#34;, &amp;#34;executor&amp;#34;: &amp;#34;shell&amp;#34;, &amp;#34;executor_config&amp;#34;: { &amp;#34;command&amp;#34;: &amp;#34;echo \&amp;#34;Hello from parent\&amp;#34;&amp;#34; }, &amp;#34;retries&amp;#34;: 5 } In case of failure to run the job in one node, it will try to run the job again in that node until the retries count reaches the limit.</description>
    </item>
    
    <item>
      <title>License</title>
      <link>/intro/license/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/intro/license/</guid>
      <description>Copyright &amp;copy; Victor Castell
Dkron is an Open Source project licensed under the terms of the LGPLv3 license. Please see http://www.gnu.org/licenses/lgpl-3.0.html for license text.</description>
    </item>
    
    <item>
      <title>Metrics</title>
      <link>/usage/metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/metrics/</guid>
      <description>Dkron has the ability to send metrics to Statsd for dashboards and historical reporting. It sends job processing metrics and golang, serf metrics too.
Configuration Add this in your yaml config file
dog_statsd_addr: &amp;#34;localhost:8125&amp;#34; Metrics  dkron.agent.event_received.query_execution_done dkron.agent.event_received.query_run_job dkron.memberlist.gossip dkron.memberlist.probeNode dkron.memberlist.pushPullNode dkron.memberlist.tcp.accept dkron.memberlist.tcp.connect dkron.memberlist.tcp.sent dkron.memberlist.udp.received dkron.memberlist.udp.sent dkron.rpc.call_execution_done dkron.rpc.call_get_job dkron.rpc.execution_done dkron.rpc.get_job dkron.runtime.alloc_bytes dkron.runtime.free_count dkron.runtime.gc_pause_ns dkron.runtime.heap_objects dkron.runtime.malloc_count dkron.runtime.num_goroutines dkron.runtime.sys_bytes dkron.runtime.total_gc_pause_ns dkron.runtime.total_gc_runs dkron.serf.coordinate.adjustment_ms dkron.serf.msgs.received dkron.serf.msgs.sent dkron.serf.queries dkron.serf.queries.execution_done dkron.serf.queries.run_job dkron.serf.query_acks dkron.serf.query_responses dkron.serf.queue.Event dkron.serf.queue.Intent dkron.</description>
    </item>
    
    <item>
      <title>Use with AWS ECS</title>
      <link>/usage/ecs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/usage/ecs/</guid>
      <description>Dkron Pro comes with a native ECS executor out of the box.
 Use with Amazon ECS To use Dkron to schedule jobs that run in containers, a wrapper ECS script is needed.
Install the following snippet in the node that will run the call to ECS
 Prerequisites The node that will run the call to ECS will need to have installed
 AWS cli jq  Example ecs-run --cluster cron --task-definition cron-taskdef --container-name cron --region us-east-1 --command &amp;quot;rake foo&amp;quot;</description>
    </item>
    
  </channel>
</rss>